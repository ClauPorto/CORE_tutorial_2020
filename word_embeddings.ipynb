{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "\n",
    "The previous analyses have shown that fake news tends to use consistently inflammatory and subjective vocabulary, and tends to cover issues that may incite controversy.\n",
    "\n",
    "Let's drill down to the word level and look for connotations among words used in both fake and real news. This could reveal underlying biases that shape how certain words like `election` or `president` are perceived.\n",
    "\n",
    "1. [Load data](#Load-data)\n",
    "2. [Train embeddings](#Train-embedding-models)\n",
    "3. [Nearest neighbors](#Look-at-nearest-neighbors)\n",
    "4. [Different neighbors](#Find-words-with-different-neighbors)\n",
    "5. [Exploration](#Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data = fake news challenge\n",
    "import pandas as pd\n",
    "fake_news_article_data = pd.read_csv('data/fake_news_challenge/Fake.csv', sep=',', index_col=False)\n",
    "real_news_article_data = pd.read_csv('data/fake_news_challenge/True.csv', sep=',', index_col=False)\n",
    "display(fake_news_article_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## clean data\n",
    "from nltk.tokenize import PunktSentenceTokenizer, WordPunctTokenizer\n",
    "sent_tokenizer = PunktSentenceTokenizer()\n",
    "word_tokenizer = WordPunctTokenizer()\n",
    "def get_sentence_word_tokens(text, word_tokenizer, sent_tokenizer):\n",
    "    text_sents = sent_tokenizer.tokenize(text)\n",
    "    text_sent_tokens = list(map(word_tokenizer.tokenize, text_sents))\n",
    "    return text_sent_tokens\n",
    "fake_news_sentences = fake_news_article_data.loc[:, 'text'].apply(lambda x: get_sentence_word_tokens(x, word_tokenizer, sent_tokenizer))\n",
    "real_news_sentences = real_news_article_data.loc[:, 'text'].apply(lambda x: get_sentence_word_tokens(x, word_tokenizer, sent_tokenizer))\n",
    "# flatten for processing\n",
    "from functools import reduce\n",
    "def flatten_list_data(data):\n",
    "    flat_data = []\n",
    "    for x in data:\n",
    "        flat_data.extend(x)\n",
    "    return flat_data\n",
    "fake_news_sentences = flatten_list_data(fake_news_sentences)\n",
    "real_news_sentences = flatten_list_data(real_news_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding models\n",
    "Let's first train the word embedding models on the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train word2vec embeddings\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "def train_word2vec_model(text_sents, model_out_file):\n",
    "    dim = 50\n",
    "    alpha = 0.025\n",
    "    window = 5\n",
    "    min_count = 5\n",
    "    model = Word2Vec(sentences=text_sents, size=dim, alpha=alpha, window=window, min_count=min_count, seed=123)\n",
    "#     model.build_vocab(text_sents)\n",
    "    model.save(model_out_file)\n",
    "fake_news_word2vec_model_out_file = 'data/fake_news_challenge/fake_news_word2vec_embed.model'\n",
    "real_news_word2vec_model_out_file = 'data/fake_news_challenge/real_news_word2vec_embed.model'\n",
    "## skipping these steps to save time during tutorial\n",
    "# train_word2vec_model(fake_news_sentences, fake_news_word2vec_model_out_file)\n",
    "# train_word2vec_model(real_news_sentences, real_news_word2vec_model_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load from file\n",
    "fake_news_word2vec_embed_model = Word2Vec.load(fake_news_word2vec_model_out_file)\n",
    "real_news_word2vec_embed_model = Word2Vec.load(real_news_word2vec_model_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train Glove embeddings\n",
    "from glove import Glove, Corpus\n",
    "def fit_glove_model(text_sents, model_out_file):\n",
    "    dim = 50\n",
    "    learning_rate = 0.05\n",
    "    alpha = 0.025\n",
    "    random_state = 123\n",
    "    train_epochs = 100\n",
    "    num_threads = 4\n",
    "    window = 5\n",
    "    glove_corpus = Corpus()\n",
    "    glove_corpus.fit(text_sents, window=window)\n",
    "    glove_embed_model = Glove(no_components=dim, learning_rate=learning_rate, \n",
    "                              alpha=alpha, random_state=random_state)\n",
    "    # note: this takes ~ 5 minutes with 4 threads on a server\n",
    "    glove_embed_model.fit(glove_corpus.matrix, epochs=train_epochs,\n",
    "                          no_threads=num_threads, verbose=True)\n",
    "    glove_embed_model.add_dictionary(glove_corpus.dictionary)\n",
    "    glove_embed_model.save(model_out_file)\n",
    "fake_news_glove_model_out_file = 'data/fake_news_challenge/fake_news_glove_embed.model'\n",
    "real_news_glove_model_out_file = 'data/fake_news_challenge/real_news_glove_embed.model'\n",
    "## skipping these steps to save time during tutorial\n",
    "# print('fitting Glove embeddings for fake news')\n",
    "# fit_glove_model(fake_news_sentences, fake_news_glove_model_out_file)\n",
    "# print('fitting Glove embeddings for real news')\n",
    "# fit_glove_model(real_news_sentences, real_news_glove_model_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload models after training\n",
    "fake_news_glove_embed_model = Glove.load(fake_news_glove_model_out_file)\n",
    "real_news_glove_embed_model = Glove.load(real_news_glove_model_out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start out by looking at the nearest neighbors for some test words. \n",
    "\n",
    "We'll get the test words by filtering from the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from stop_words import get_stop_words\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "news_word_counter = Counter()\n",
    "for sent_i in fake_news_sentences:\n",
    "    news_word_counter.update(sent_i)\n",
    "for sent_i in real_news_sentences:\n",
    "    news_word_counter.update(sent_i)\n",
    "news_word_counts = pd.Series(dict(news_word_counter)).sort_values(inplace=False, ascending=False)\n",
    "en_stops = set(get_stop_words('en')) & set(news_word_counts.index)\n",
    "news_word_counts.drop(en_stops, inplace=True)\n",
    "display(news_word_counts.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = ['Trump', 'President', 'election', 'Republicans', 'Democratic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test word2vec first\n",
    "N_neighbors = 10\n",
    "for test_word_i in test_words:\n",
    "    print(f'testing word = {test_word_i}')\n",
    "    print(f'\\tfake news neighbors')\n",
    "    print(fake_news_word2vec_embed_model.most_similar(test_word_i, topn=N_neighbors))\n",
    "    print(f'\\treal news neighbors')\n",
    "    print(real_news_word2vec_embed_model.most_similar(test_word_i, topn=N_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test Glove embeddings\n",
    "N_neighbors = 10\n",
    "for test_word_i in test_words:\n",
    "    print(f'testing word = {test_word_i}')\n",
    "    print(f'\\tfake news neighbors')\n",
    "    print(fake_news_glove_embed_model.most_similar(test_word_i, number=N_neighbors))\n",
    "    print(f'\\treal news neighbors')\n",
    "    print(real_news_glove_embed_model.most_similar(test_word_i, number=N_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some aspects of potential bias with these test words.\n",
    "\n",
    "For `word2vec`:\n",
    "- `Trump` is associated with almost exclusively Republican politicians in fake news and with a mix of politicians in real news\n",
    "- `President` is associated more with U.S. politics in fake news and more with international politicians in real news\n",
    "- `Democratic` are associated more with U.S. politics in fake news and more with international politics in real news\n",
    "\n",
    "For `Glove`:\n",
    "- `Trump` is associated with himself (and news network? `Q13FOXWATCH`) in fake news and with other presidents in real news\n",
    "- `President` is associated with Trump and Obama in fake news and more with international politicians in real news\n",
    "- `Democratic` is associated with U.S. party politics in both fake and real news\n",
    "\n",
    "This qualitative analysis helps us understand that some words may indeed have significant divergence in their connotations between the different data sets, while others are more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find words with different neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which words are the most different across the data?\n",
    "\n",
    "We'll measure \"difference\" using the overlap in nearest neighbors (i.e. Jaccard similarity).\n",
    "\n",
    "$$\\text{diff(word1, word2)} = 1 - \\frac{\\text{neighbors(word1)} \\: \\cap \\: \\text{neighbors(word2)}}{\\text{neighbors(word1)} \\cup \\text{neighbors(word2)}}$$\n",
    "\n",
    "A difference of 100% means that the words have no neighbors in common, while a difference of 0% means that the words have identical neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_neighbor_diff(neighbors_1, neighbors_2):\n",
    "    neighbor_intersect = set(neighbors_1) & set(neighbors_2)\n",
    "    neighbor_union = set(neighbors_1) | set(neighbors_2)\n",
    "    neighbor_diff = 1 - len(neighbor_intersect) / len(neighbor_union)\n",
    "    return neighbor_diff\n",
    "def compute_neighbor_diff_model(word, model_1, model_2, N_neighbor, model_type='word2vec'):\n",
    "    if(model_type == 'word2vec'):\n",
    "        neighbors_1, neighbor_scores_1 = zip(*model_1.wv.most_similar(word, topn=N_neighbor))\n",
    "        neighbors_2, neighbor_scores_2 = zip(*model_2.wv.most_similar(word, topn=N_neighbor))\n",
    "    elif(model_type == 'glove'):\n",
    "        neighbors_1, neighbor_scores_1 = zip(*model_1.most_similar(word, number=N_neighbor))\n",
    "        neighbors_2, neighbor_scores_2 = zip(*model_2.most_similar(word, number=N_neighbor))\n",
    "    neighbor_diff = compute_neighbor_diff(neighbors_1, neighbors_2)\n",
    "    return neighbor_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shared vocabulary\n",
    "shared_word2vec_vocab = list(set(fake_news_word2vec_embed_model.wv.vocab.keys()) & set(real_news_word2vec_embed_model.wv.vocab.keys()))\n",
    "print(f'{len(shared_word2vec_vocab)} words in word2vec vocab')\n",
    "# compute neighbor differences for all valid words\n",
    "model_type = 'word2vec'\n",
    "N_neighbor = 10\n",
    "fake_vs_real_word2vec_neighbor_diffs = list(map(lambda x: compute_neighbor_diff_model(x, fake_news_word2vec_embed_model, real_news_word2vec_embed_model, N_neighbor, model_type=model_type), shared_word2vec_vocab))\n",
    "# add vocabulary as index\n",
    "fake_vs_real_word2vec_neighbor_diffs = pd.Series(fake_vs_real_word2vec_neighbor_diffs, index=shared_word2vec_vocab)\n",
    "fake_vs_real_word2vec_neighbor_diffs.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 20\n",
    "print('words with most neighbor difference')\n",
    "print(fake_vs_real_word2vec_neighbor_diffs.head(top_k))\n",
    "print('words with most neighbor similarity')\n",
    "print(fake_vs_real_word2vec_neighbor_diffs.tail(top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words with the biggest neighbor differences don't seem to be super informative and may reflect topical differences (e.g. fake news tends to discuss `Charlie` more often and therefore has more consistent nearest neighbors).\n",
    "\n",
    "What if we restrict to the top-1000 most frequent words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the words that are in the word2vec vocab\n",
    "word2vec_vocab_news_word_counts = news_word_counts.loc[(news_word_counts.index & set(shared_word2vec_vocab))].sort_values(inplace=False, ascending=False)\n",
    "top_N_words = word2vec_vocab_news_word_counts.iloc[:1000].index.tolist()\n",
    "top_N_fake_vs_real_word2vec_neighbor_diffs = fake_vs_real_word2vec_neighbor_diffs.loc[top_N_words].sort_values(inplace=False, ascending=False)\n",
    "top_k = 50\n",
    "print('frequent words with most neighbor difference')\n",
    "print(top_N_fake_vs_real_word2vec_neighbor_diffs.head(top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! This leaves us with some interesting words to investigate:\n",
    "\n",
    "- `left` (related to politics?)\n",
    "- `Barack`\n",
    "- `twitter`\n",
    "- `Black`\n",
    "- `Islamic`\n",
    "- `corruption`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print neighbors for all high-difference words\n",
    "high_diff_words = ['left', 'Barack', 'twitter', 'Black', 'Islamic', 'corruption']\n",
    "N_neighbors = 10\n",
    "for word_i in high_diff_words:\n",
    "    print(f'testing word = {word_i}')\n",
    "    print(f'\\tfake news neighbors')\n",
    "    print(fake_news_word2vec_embed_model.most_similar(word_i, topn=N_neighbors))\n",
    "    print(f'\\treal news neighbors')\n",
    "    print(real_news_word2vec_embed_model.most_similar(word_i, topn=N_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals some serious bias going on in the fake news articles.\n",
    "\n",
    "- `left` is more associated with extreme political views in fake news, and more associated with the traditional verb sense in real news\n",
    "- `Barack` is more associated with the Obama administration (and his \"unusual\" name `Hussein`) in fake news, and more associated with world leaders in real news\n",
    "- `twitter` is more associated with \"alternative\" news sources in fake news, and more associated with social media in general in real news\n",
    "- `Black` is more associated with the Black Lives Matter movement and other left-wing movements (`antifa`) in fake news, and more associated with a variety of organizations in real news\n",
    "- `Islamic` is more associated with terrorist and perceived \"radical\" movements in fake news, and more associated with Middle Eastern politics in real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: visualize?? https://stackoverflow.com/questions/43776572/visualise-word2vec-generated-from-gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "Now it's time for you to try out some more tests with word embeddings!\n",
    "\n",
    "- Increasing the **window size** when training embeddings can help the embeddings capture more global context (e.g. associating `tomato` with cooking details from the wider sentence context). How would this help capture divides between fake news and real news?\n",
    "- One way to determine the **connotation** of a word in embedding space is to look at its proximity to positive and negative words: e.g. if `Barack` is consistently closer to words like `bad` and `terrible` than to `good` and `nice`. Can you come up with a way to test word connotations using this kind of approach, and determine whether some words have consistently better or worse connotations in fake news articles?\n",
    "- Another useful aspect of word embeddings is their tendency to **cluster** words into general semantic fields, e.g. grouping all politician names near one another. Using the visualization technique from earlier, try to find words that (1) consistently fall into neat clusters and (2) sometimes appear outside of the expected clusters in the data. Which political and organizational words tend to be represented outside of their expected cluster, and why do you think that happens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CORE_tutorial] *",
   "language": "python",
   "name": "conda-env-CORE_tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
